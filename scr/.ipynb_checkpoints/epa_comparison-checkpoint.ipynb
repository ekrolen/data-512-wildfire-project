{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa05fe79",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this scipt is to compare our annual estimates of air quality in Pahrump, NV to the EPA's Air Quality Index (AQI). We will reuse code developed by Professor McDonald, noted throughout the notebook. His code is for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.1 - September 5, 2023.\n",
    "\n",
    "We will begin by reading in python libraries and our annual smoke estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed08d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json, time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#Reading in the annual smoke estimate\n",
    "smoke_est = pd.read_csv('../clean_data/annual_smoke_estimate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e445a",
   "metadata": {},
   "source": [
    "Creating constants which will be referenced throughout this code. Code originally developed by Professor McDonald, edited by Emily Creeden. Update information to reflect your own email, key, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e080109",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'ekrolen@uw.edu'\n",
    "APIKEY = 'amberfox47'\n",
    "\n",
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "# \n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27017d",
   "metadata": {},
   "source": [
    "The user may need to sign up for the EPA's API - the code to do so can be uncommented below. If the use loses their key, they can sign up again using this code. Be sure to update the email value with your own email. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1284da76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Request email\\ndef request_signup(email_address = None,\\n                   endpoint_url = API_REQUEST_URL, \\n                   endpoint_action = API_ACTION_SIGNUP, \\n                   request_template = AQS_REQUEST_TEMPLATE,\\n                   headers = None):\\n    \\n    # Make sure we have a string - if you don\\'t have access to this email addres, things might go badly for you\\n    if email_address:\\n        request_template[\\'email\\'] = email_address        \\n    if not request_template[\\'email\\']: \\n        raise Exception(\"Must supply an email address to call \\'request_signup()\\'\")\\n    \\n    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\\n    request_url = endpoint_url+endpoint_action.format(**request_template)\\n        \\n    # make the request\\n    try:\\n        # Wait first, to make sure we don\\'t exceed a rate limit in the situation where an exception occurs\\n        # during the request processing - throttling is always a good practice with a free data source\\n        if API_THROTTLE_WAIT > 0.0:\\n            time.sleep(API_THROTTLE_WAIT)\\n        response = requests.get(request_url, headers=headers)\\n        json_response = response.json()\\n    except Exception as e:\\n        print(e)\\n        json_response = None\\n    return json_response\\n\\nprint(\"Requesting SIGNUP ...\")\\nresponse = request_signup(\"ekrolen@uw.edu\")\\nprint(json.dumps(response,indent=4))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Request email\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL, \n",
    "                   endpoint_action = API_ACTION_SIGNUP, \n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "    \n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address        \n",
    "    if not request_template['email']: \n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "    \n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "print(\"Requesting SIGNUP ...\")\n",
    "response = request_signup(\"ekrolen@uw.edu\")\n",
    "print(json.dumps(response,indent=4))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04514056",
   "metadata": {},
   "source": [
    "We will need to get information about different air quality monitoring stations and the particulates they observe. We start by creating a list request. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa9a3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors \n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL, \n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES, \n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "    \n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    \n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783c8d9",
   "metadata": {},
   "source": [
    "Now we need to get information on classes of sensors so we can ultimately get the sensor ID numbers for the sensors near our town. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a89a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "#To see information on measurements, uncomment the below\n",
    "#if response[\"Header\"][0]['status'] == \"Success\":\n",
    "#    print(json.dumps(response['Data'],indent=4))\n",
    "#else:\n",
    "#    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1623c2",
   "metadata": {},
   "source": [
    "We are looking for AQI measurements, so we should select the sensors which measure AQI. Based on the output above we will use the AQI POLLUTANTS sensor group to get sensor ids for the individual sensors. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d80709",
   "metadata": {},
   "outputs": [],
   "source": [
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\"\n",
    "\n",
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "#To see individual pollutants and their codes, uncomment the below\n",
    "#if response[\"Header\"][0]['status'] == \"Success\":\n",
    "#    print(json.dumps(response['Data'],indent=4))\n",
    "#else:\n",
    "#    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc39cb",
   "metadata": {},
   "source": [
    "Using the above output we can see what sensor codes correspond to each element of AQI. There are gases and particulates both included in AQI measurements, and their codes are listed below. We need to break up the two kinds of sensors due to API restrictions on how many codes can be included in the pull. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf5309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "#\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\"\n",
    "#   \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb895fb8",
   "metadata": {},
   "source": [
    "We will be looking for AQI sensors near Pahrump. We include the town's information below for future calls. Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e3e970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Pahrump information\n",
    "CITY_LOCATIONS = {\n",
    "    'pahrump' :       {'city'   : 'Pahrump',\n",
    "                       'county' : 'Nye',\n",
    "                       'state'  : 'Nevada',\n",
    "                       'fips'   : '32023', #Combination of state (32) and county (023) FIPS codes\n",
    "                       'latlon' : [36.231143, -116.017339]}, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ed5ce",
   "metadata": {},
   "source": [
    "We will now return all the EPA monitoring sites within Nye County (the county containing Pahrump, NV). Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0bbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['pahrump']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['pahrump']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "#To see the individual sensor codes and locations, uncomment the below\n",
    "#if response[\"Header\"][0]['status'] == \"Success\":\n",
    "#    print(json.dumps(response['Data'],indent=4))\n",
    "#else:\n",
    "#    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a942feb",
   "metadata": {},
   "source": [
    "We now need to get outputs from the local AQI stations. For this we pull daily summary requests. Per Professor McDonald's note, \"The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges.\" Code originally developed by Professor McDonald, edited by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1a0fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date. \n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0ea40",
   "metadata": {},
   "source": [
    "The below code sets up the parameters and constants necessary to extract the summary sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec83530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up requests to the EPA's APIs\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['pahrump']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['pahrump']['fips'][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea1c5",
   "metadata": {},
   "source": [
    "The below code returns daily summaries for AQI elements collected from local sensors near Pahrump, NV. We will only be collecting data during fire season given we are going to compare it with wildland fire smoke estimates and most fires occurr during fire season (May 1st-Oct 31st). Additionally, while some stations may produce granular AQI measurements (e.g., on the hourly scale), \"The Air Quality Index is based on daily air quality summaries, specifically daily maximums or daily\n",
    "averages. It is not valid to use shorter-term (e.g. hourly) data to calculate an AQI value.\" [Technical Assistance Document for the Reporting of Daily Air Quality â€“ the Air Quality Index (AQI)](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf) Due to this standard, we will only use the 24-HR BLK AVG AQI measurement for each gas/particulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AQI data for 1963...\n",
      "Processing AQI data for 1968...\n"
     ]
    }
   ],
   "source": [
    "#Making the list of years\n",
    "year_list = []\n",
    "for value in range(1963, 2024):\n",
    "    year_list.append(value)\n",
    "\n",
    "AQI_df = pd.DataFrame(columns = ['site_number', 'parameter_code', 'sample_duration','date_local','aqi'])\n",
    "#Querying the API repeatedly\n",
    "for year in year_list:\n",
    "    if (1963-year) % 5 == 0 or year == 1963:\n",
    "        print(\"Processing AQI data for {0}...\".format(year))\n",
    "    start_date = str(year)+'0501'\n",
    "    terminate_date = str(year)+'1031'\n",
    "    #Getting gaseous information\n",
    "    request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=start_date, end_date=terminate_date)\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        for datum in gaseous_aqi['Data']:\n",
    "            if datum['sample_duration'] == '24-HR BLK AVG':\n",
    "                    AQI_df = df.append({'site_number':datum['site_number'],\n",
    "                                        'parameter_code':datum['parameter_code'],\n",
    "                                        'sample_duration':datum['sample_duration'],\n",
    "                                        'date_local':datum['date_local'],\n",
    "                                        'aqi':datum['aqi']\n",
    "                                        }, ignore_index = True)\n",
    "            else: pass\n",
    "    else: pass\n",
    "    #Getting particulate information\n",
    "    request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=start_date, end_date=terminate_date)\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        for datum in particulate_aqi['Data']:\n",
    "            if datum['sample_duration'] == '24-HR BLK AVG':\n",
    "                AQI_df = AQI_df.append({'site_number':datum['site_number'],\n",
    "                                    'parameter_code':datum['parameter_code'],\n",
    "                                    'sample_duration':datum['sample_duration'],\n",
    "                                    'date_local':datum['date_local'],\n",
    "                                    'aqi':datum['aqi']\n",
    "                                    }, ignore_index = True)\n",
    "            else: pass\n",
    "    else: pass\n",
    "    #Save intermediate outputs\n",
    "    if (1963-year) % 20 == 0:\n",
    "        AQI_df.to_csv(\"../intermediate_data/unaggregated_aqi.csv\", index = None)\n",
    "\n",
    "#Save final DF to file\n",
    "AQI_df.to_csv(\"../intermediate_data/unaggregated_aqi.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5574e62",
   "metadata": {},
   "source": [
    "Now we will examine the AQI data pulled from sensors in and around Pahrump, NV. We can see that some sensors do not collect any data (e.g., sensors 0001, 0002, 0003, 0004), and our local sensors only collect information on particulate matter with a diameter of 10 microns or less (PM10 Total 0-10um STP, code 81102)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AQI_df.head())\n",
    "print(\"The stations which return AQI information are: {0}\".format(AQI_df['site_number'].unique()))\n",
    "print(\"The pollutants returned are: {0}\".format(AQI_df['parameter_code'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097b3cd",
   "metadata": {},
   "source": [
    "Because local stations in Nye County only pull one type of particulate matter, there is no need to find the max particulate AQI per station as is typical with AQI calculations. Instead, we will move on to create a yearly AQI average for stations within Nye county. We will average over all stations per day per year. We do not take the average of the daily max AQI for all stations because we want to get a sense of the air quality of Pahrump on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the AQI df in the event that the programmer took a break\n",
    "AQI_df = pd.read_csv('../intermediate_data/unaggregated_aqi.csv')\n",
    "\n",
    "#Adding year col to the df\n",
    "AQI_df['year'] = AQI_df['date_local'].str[:4]\n",
    "\n",
    "#Grouping by year and averaging the AQI\n",
    "yearly_avg_AQI = AQI_df.groupby('year')['aqi'].mean().to_frame('annual_avg_aqi').reset_index()\n",
    "\n",
    "#Saving annual avg AQI\n",
    "yearly_avg_AQI.to_csv('../clean_data/yearly_avg_aqi.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c1689",
   "metadata": {},
   "source": [
    "Now we will compare our smoke estimates to the annual AQI estimates. To ensure we are comparing like for like we will normalize the data and plot a linear regression noting the correlation via \"r\". The linear regression code was modified from [W3 Schools](https://www.w3schools.com/python/python_ml_linear_regression.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the smoke estimates and AQI data\n",
    "smoke_est = pd.read_csv('../clean_data/annual_smoke_estimate.csv')\n",
    "aqi_est = pd.read_csv('../clean_data/yearly_avg_aqi.csv')\n",
    "\n",
    "#Inner joining the datasets\n",
    "smoke_aqi = pd.merge(left = smoke_est, right = aqi_est, how = \"inner\", left_on = 'Fire_Year', right_on = 'year')\n",
    "smoke_aqi.head()\n",
    "\n",
    "#Normalizing the columns\n",
    "df_min_max_scaled = smoke_aqi.copy() \n",
    "df_min_max_scaled['scaled_smoke'] = (df_min_max_scaled['Annual_Smoke_Estimate'] - df_min_max_scaled['Annual_Smoke_Estimate'].min()) / (df_min_max_scaled['Annual_Smoke_Estimate'].max() - df_min_max_scaled['Annual_Smoke_Estimate'].min())     \n",
    "df_min_max_scaled['scaled_aqi'] = (df_min_max_scaled['annual_avg_aqi'] - df_min_max_scaled['annual_avg_aqi'].min()) / (df_min_max_scaled['annual_avg_aqi'].max() - df_min_max_scaled['annual_avg_aqi'].min())     \n",
    "\n",
    "#Graphing the two columns to see the relationship\n",
    "x = df_min_max_scaled['scaled_aqi']\n",
    "y = df_min_max_scaled['scaled_smoke']\n",
    "\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "def line_eqn(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "mymodel = list(map(line_eqn, x))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, mymodel)\n",
    "plt.xlabel('Scaled AQI', size=12)\n",
    "plt.ylabel('Scaled Smoke Estimate', size=12)\n",
    "plt.title('Scaled Smoke Estimate vs. Scaled AQI for Pahrump, NV', size=16)\n",
    "plt.show()\n",
    "\n",
    "print(\"The r-squared value for the linear regression is {0}.\".format(round(r,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33f309",
   "metadata": {},
   "source": [
    "From the above calculation we can see that our smoke estimators and AQI estimators are positively correlated, but the coefficient of correlation isn't very strong, only 0.13. Ideally we would have a correlation in the 0.7 to 1.0 range to indicate strong alignment. However, we should remember that our smoke estimate is relatively simplistic and misses important factors such as weather, fire fuel, topography, etc. Additionally, our EPA monitoring stations only track data for one particulate, rather than a combination of particulate and gaseous factors, limiting our overall AQI metric. In summary, we are pleased to see a positive correlation, but do wish the strength of correlation was higher. If given more time, it would be interesting to tweak the smoke estimates (e.g., alter the formula, consider only certain kinds of fires) and AQI measurements (e.g., find additional monitoring stations, calculate the max AQI vs. average AQI) to see if we could get stronger correlation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
