{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1338387",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this file is to filter the raw data into the information we need to create smoke estimators. Specifically we need to limit the data to: \n",
    "1. Fires within 1250 miles of Pahrump, Nevada (Nye County)\n",
    "2. Fires which occurred within the last 60 years (1963-2023)\n",
    "\n",
    "We will begin by importing some python libraries. The user may need to install pyproj (converts between different geodesic coordinate systems and calculates distances between points (coordinates) in a specific geodesic system) and geojson using pip. The 'wildfire' module is a user-created module. This module is available from the [course website](https://drive.google.com/drive/folders/1OJktGAx86hvMtirCUkGnS292r-FpPvLo) and must be unzipped and moved into the folder pointed to by your PYTHONPATH system variable. The module includes one object, a Reader, that can be used to read the GeoJSON files associated with the wildefire dataset. The module also contains a sample datafile that is GeoJSON compliant and that contains a small number of California wildfires extracted from the main wildfire dataset. \n",
    "\n",
    "\n",
    "Some of the code below was taken from the wildfire_geo_proximity_example notebook created by Professor McDonald. [The notebook](https://drive.google.com/drive/folders/1OJktGAx86hvMtirCUkGnS292r-FpPvLo) and module are licensed for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.0 - August 13, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010701b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from pyproj import Transformer, Geod\n",
    "from wildfire.Reader import Reader as WFReader\n",
    "import geojson\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75f4a1",
   "metadata": {},
   "source": [
    "Transform the feature geometry into different coordinate system (EPSG:4326). Code originally written by Professor McDonald, modified by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a64c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Transform feature geometry data\n",
    "#\n",
    "#    The function takes one parameter, a list of ESRI:102008 coordinates that will be transformed to EPSG:4326\n",
    "#    The function returns a list of coordinates in EPSG:4326\n",
    "def convert_ring_to_epsg4326(ring_data=None):\n",
    "    converted_ring = list()\n",
    "    #\n",
    "    # We use a pyproj transformer that converts from ESRI:102008 to EPSG:4326 to transform the list of coordinates\n",
    "    to_epsg4326 = Transformer.from_crs(\"ESRI:102008\",\"EPSG:4326\")\n",
    "    # We'll run through the list transforming each ESRI:102008 x,y coordinate into a decimal degree lat,lon\n",
    "    for coord in ring_data:\n",
    "        lat,lon = to_epsg4326.transform(coord[0],coord[1])\n",
    "        new_coord = lat,lon\n",
    "        converted_ring.append(new_coord)\n",
    "    return converted_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a744b3c",
   "metadata": {},
   "source": [
    "Next we need to find the shortest distance between our city and each fire. We choose to measure the distance from the perimeter of the fire rather than the center of the fire. We do this because we believe proximity to town is important in determining the amount of smoke generated. The edge of the fire may be close to town, whereas the center of the fire may be several miles away, underestimating the amount of local smoke. We estimate the town's coordinates to be in the middle of Pahrump as shown on GoogleMaps. We do this because we want to estimate smoke for the town as a whole and did not want to bias towards one side or another. We will later calculate the smoke estimate using the proximity to town.\n",
    "\n",
    "Code originally written by Professor McDonald, modified by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c16c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    The function takes two parameters\n",
    "#        A place - which is coordinate point (list or tuple with two items, (lat,lon) in decimal degrees EPSG:4326\n",
    "#        Ring_data - a list of decimal degree coordinates for the fire boundary\n",
    "#\n",
    "#    The function returns a list containing the shortest distance to the perimeter and the point where that is\n",
    "#\n",
    "def shortest_distance_from_place_to_fire_perimeter(place=None,ring_data=None):\n",
    "    # convert the ring data to the right coordinate system\n",
    "    ring = convert_ring_to_epsg4326(ring_data)    \n",
    "    # create a epsg4326 compliant object - which is what the WGS84 ellipsoid is\n",
    "    geodcalc = Geod(ellps='WGS84')\n",
    "    closest_point = list()\n",
    "    # run through each point in the converted ring data\n",
    "    for point in ring:\n",
    "        # calculate the distance\n",
    "        d = geodcalc.inv(place[1],place[0],point[1],point[0])\n",
    "        # convert the distance to miles\n",
    "        distance_in_miles = d[2]*0.00062137\n",
    "        # if it's closer to the city than the point we have, save it\n",
    "        if not closest_point:\n",
    "            closest_point.append(distance_in_miles)\n",
    "            closest_point.append(point)\n",
    "        elif closest_point and closest_point[0]>distance_in_miles:\n",
    "            closest_point = list()\n",
    "            closest_point.append(distance_in_miles)\n",
    "            closest_point.append(point)\n",
    "    return closest_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb7051",
   "metadata": {},
   "source": [
    "Now we will load the geojson fire data into the wildfire reader. Code originally written by Professor McDonald, modified by Emily Creeden.\n",
    "\n",
    "*Users should change SAMPLE_DATA_FILENAME to reflect where they have stored the USGS_Wildland_Fire_Combined_Dataset.json if not 2 directories above the current directory as specified in the README.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42f148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open '../../USGS_Wildland_Fire_Combined_Dataset.json' with wildfire.Reader() object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#    This bit of code opens a new wildfire reader, gets the header information and prints it to the screen\n",
    "#\n",
    "SAMPLE_DATA_FILENAME = '../../USGS_Wildland_Fire_Combined_Dataset.json'\n",
    "print(f\"Attempting to open '{SAMPLE_DATA_FILENAME}' with wildfire.Reader() object\")\n",
    "wfreader = WFReader(SAMPLE_DATA_FILENAME)\n",
    "print()\n",
    "#\n",
    "#    OPTIONAL: Now print the header - it contains some useful information\n",
    "#\n",
    "#header_dict = wfreader.header()\n",
    "#header_keys = list(header_dict.keys())\n",
    "#print(\"The header has the following keys:\")\n",
    "#print(gj_keys)\n",
    "#print()\n",
    "#print(\"Header Dictionary\")\n",
    "#print(json.dumps(header_dict,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f83d17",
   "metadata": {},
   "source": [
    "Next we will get a list of features (fires) in the data. This section may take a while to run. Code originally written by Professor McDonald, modified by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d876b198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 features\n",
      "Loaded 20000 features\n",
      "Loaded 30000 features\n",
      "Loaded 40000 features\n",
      "Loaded 50000 features\n",
      "Loaded 60000 features\n",
      "Loaded 70000 features\n",
      "Loaded 80000 features\n",
      "Loaded 90000 features\n",
      "Loaded 100000 features\n",
      "Loaded 110000 features\n",
      "Loaded 120000 features\n",
      "Loaded 130000 features\n",
      "Loaded a total of 135061 features\n",
      "Variable 'feature_list' contains 135061 features\n"
     ]
    }
   ],
   "source": [
    "#Loading all feature data from raw USGS data.\n",
    "MAX_FEATURE_LOAD = 100\n",
    "feature_list = list()\n",
    "feature_count = 0\n",
    "# A rewind() on the reader object makes sure we're at the start of the feature list\n",
    "## This way, we can execute this cell multiple times and get the same result \n",
    "wfreader.rewind()\n",
    "# Now, read through each of the features, saving them as dictionaries into a list\n",
    "feature = wfreader.next()\n",
    "while feature:\n",
    "    feature_list.append(feature)\n",
    "    feature_count += 1\n",
    "    # if we're loading a lot of features, print progress\n",
    "    if (feature_count % 10000) == 0:\n",
    "        print(f\"Loaded {feature_count} features\")\n",
    "    # loaded the max we're allowed then break\n",
    "    '''if feature_count >= MAX_FEATURE_LOAD:\n",
    "        break'''\n",
    "    feature = wfreader.next()\n",
    "#\n",
    "#    Print the number of items (features) we think we loaded\n",
    "print(f\"Loaded a total of {feature_count} features\")\n",
    "#\n",
    "#    Just a validation check - did all the items we loaded get into the list?\n",
    "print(f\"Variable 'feature_list' contains {len(feature_list)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56568c98",
   "metadata": {},
   "source": [
    "Next we specify the coordinates of the town you want to measure distances from. As noted above, we use the center of Pahrump as a proxy to the whole town. Code originally written by Professor McDonald, modified by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889d3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building out the city location\n",
    "CITY_LOCATIONS = {\n",
    "    'pahrump' :     {'city'   : 'Pahrump', \n",
    "                     'latlon' : [36.231143, -116.017339]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4cb6cb",
   "metadata": {},
   "source": [
    "The below code calculates the distance from the closest edge of the fire to the center of town. It may run for ~1 hour. Code originally written by Professor McDonald, modified by Emily Creeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd6e45f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 features\n",
      "Processed 2000 features\n",
      "Processed 3000 features\n",
      "Processed 4000 features\n",
      "Processed 5000 features\n",
      "Processed 6000 features\n",
      "Processed 7000 features\n",
      "Processed 8000 features\n",
      "Processed 9000 features\n",
      "Processed 10000 features\n",
      "Processed 11000 features\n",
      "Processed 12000 features\n",
      "Processed 13000 features\n",
      "Processed 14000 features\n",
      "Processed 15000 features\n",
      "Processed 16000 features\n",
      "Processed 17000 features\n",
      "Processed 18000 features\n",
      "Processed 19000 features\n",
      "Processed 20000 features\n",
      "Processed 21000 features\n",
      "Processed 22000 features\n",
      "Processed 23000 features\n",
      "Processed 24000 features\n",
      "Processed 25000 features\n",
      "Processed 26000 features\n",
      "Processed 27000 features\n",
      "Processed 28000 features\n",
      "Processed 29000 features\n",
      "Processed 30000 features\n",
      "Processed 31000 features\n",
      "Processed 32000 features\n",
      "Processed 33000 features\n",
      "Processed 34000 features\n",
      "Processed 35000 features\n",
      "Processed 36000 features\n",
      "Processed 37000 features\n",
      "Processed 38000 features\n",
      "Processed 39000 features\n",
      "Processed 40000 features\n",
      "Processed 41000 features\n",
      "Processed 42000 features\n",
      "Processed 43000 features\n",
      "Processed 44000 features\n",
      "Processed 45000 features\n",
      "Processed 46000 features\n",
      "Processed 47000 features\n",
      "Processed 48000 features\n",
      "Processed 49000 features\n",
      "Processed 50000 features\n",
      "Processed 51000 features\n",
      "Processed 52000 features\n",
      "Processed 53000 features\n",
      "Processed 54000 features\n",
      "Processed 55000 features\n",
      "Processed 56000 features\n",
      "Processed 57000 features\n",
      "Processed 58000 features\n",
      "Processed 59000 features\n",
      "Processed 60000 features\n",
      "Processed 61000 features\n",
      "Processed 62000 features\n",
      "Processed 63000 features\n",
      "Processed 64000 features\n",
      "Processed 65000 features\n",
      "Processed 66000 features\n",
      "Processed 67000 features\n",
      "Processed 68000 features\n",
      "Processed 69000 features\n",
      "Processed 70000 features\n",
      "Processed 71000 features\n",
      "Processed 72000 features\n",
      "Processed 73000 features\n",
      "Processed 74000 features\n",
      "Processed 75000 features\n",
      "Processed 76000 features\n",
      "Processed 77000 features\n",
      "Processed 78000 features\n",
      "Processed 79000 features\n",
      "Processed 80000 features\n",
      "Processed 81000 features\n",
      "Processed 82000 features\n",
      "Processed 83000 features\n",
      "Processed 84000 features\n",
      "Processed 85000 features\n",
      "Processed 86000 features\n",
      "Processed 87000 features\n",
      "Processed 88000 features\n",
      "Processed 89000 features\n",
      "Processed 90000 features\n",
      "Processed 91000 features\n",
      "Processed 92000 features\n",
      "Processed 93000 features\n",
      "Processed 94000 features\n",
      "Processed 95000 features\n",
      "Processed 96000 features\n",
      "Processed 97000 features\n",
      "Processed 98000 features\n",
      "Processed 99000 features\n",
      "Processed 100000 features\n",
      "Processed 101000 features\n",
      "Processed 102000 features\n",
      "Processed 103000 features\n",
      "Processed 104000 features\n",
      "Processed 105000 features\n",
      "Processed 106000 features\n",
      "Processed 107000 features\n",
      "Processed 108000 features\n",
      "Processed 109000 features\n",
      "109605 fire is in curveRings shape, ignoring.\n",
      "Processed 110000 features\n",
      "110224 fire is in curveRings shape, ignoring.\n",
      "110639 fire is in curveRings shape, ignoring.\n",
      "Processed 111000 features\n",
      "111431 fire is in curveRings shape, ignoring.\n",
      "111776 fire is in curveRings shape, ignoring.\n",
      "111897 fire is in curveRings shape, ignoring.\n",
      "Processed 112000 features\n",
      "112410 fire is in curveRings shape, ignoring.\n",
      "112415 fire is in curveRings shape, ignoring.\n",
      "Processed 113000 features\n",
      "113411 fire is in curveRings shape, ignoring.\n",
      "113665 fire is in curveRings shape, ignoring.\n",
      "113738 fire is in curveRings shape, ignoring.\n",
      "113766 fire is in curveRings shape, ignoring.\n",
      "113805 fire is in curveRings shape, ignoring.\n",
      "Processed 114000 features\n",
      "114309 fire is in curveRings shape, ignoring.\n",
      "114322 fire is in curveRings shape, ignoring.\n",
      "Processed 115000 features\n",
      "115629 fire is in curveRings shape, ignoring.\n",
      "115974 fire is in curveRings shape, ignoring.\n",
      "Processed 116000 features\n",
      "116235 fire is in curveRings shape, ignoring.\n",
      "Processed 117000 features\n",
      "117086 fire is in curveRings shape, ignoring.\n",
      "Processed 118000 features\n",
      "Processed 119000 features\n",
      "119582 fire is in curveRings shape, ignoring.\n",
      "119617 fire is in curveRings shape, ignoring.\n",
      "119751 fire is in curveRings shape, ignoring.\n",
      "119982 fire is in curveRings shape, ignoring.\n",
      "Processed 120000 features\n",
      "120212 fire is in curveRings shape, ignoring.\n",
      "120431 fire is in curveRings shape, ignoring.\n",
      "120678 fire is in curveRings shape, ignoring.\n",
      "120743 fire is in curveRings shape, ignoring.\n",
      "Processed 121000 features\n",
      "121010 fire is in curveRings shape, ignoring.\n",
      "Processed 122000 features\n",
      "122264 fire is in curveRings shape, ignoring.\n",
      "122531 fire is in curveRings shape, ignoring.\n",
      "Processed 123000 features\n",
      "123761 fire is in curveRings shape, ignoring.\n",
      "Processed 124000 features\n",
      "124535 fire is in curveRings shape, ignoring.\n",
      "Processed 125000 features\n",
      "125046 fire is in curveRings shape, ignoring.\n",
      "125745 fire is in curveRings shape, ignoring.\n",
      "Processed 126000 features\n",
      "Processed 127000 features\n",
      "127492 fire is in curveRings shape, ignoring.\n",
      "Processed 128000 features\n",
      "Processed 129000 features\n",
      "Processed 130000 features\n",
      "Processed 131000 features\n",
      "Processed 132000 features\n",
      "Processed 133000 features\n",
      "Processed 134000 features\n",
      "Processed 135000 features\n"
     ]
    }
   ],
   "source": [
    "#    Get a city from our CITY_LOCATIONS constant as our starting position\n",
    "place = CITY_LOCATIONS[\"pahrump\"]\n",
    "\n",
    "fire_id = []\n",
    "shortest_dist_from_edge = []\n",
    "features_processed = 0\n",
    "\n",
    "for wf_feature in feature_list:\n",
    "    #Try/Except to catch fires which aren't in a ring shape\n",
    "    try:\n",
    "        ring_data = wf_feature['geometry']['rings'][0]\n",
    "        distance = shortest_distance_from_place_to_fire_perimeter(place['latlon'],ring_data)\n",
    "        fire_id.append(wf_feature['attributes']['OBJECTID'])\n",
    "        shortest_dist_from_edge.append(round(distance[0], 2))\n",
    "    except KeyError:\n",
    "        print(\"{0} fire is in {1} shape, ignoring.\".format(wf_feature['attributes']['OBJECTID'], list(wf_feature['geometry'].keys())[0]))\n",
    "    #Incrementing the fires processed counter and saving every 10000 entries to avoid lost work\n",
    "    features_processed = features_processed + 1\n",
    "    if features_processed % 1000 == 0:\n",
    "        print(\"Processed {0} features\".format(features_processed))\n",
    "    if features_processed % 10000 == 0:\n",
    "        dist_df = pd.DataFrame({'OBJECTID': fire_id, 'shortest_dist': shortest_dist_from_edge})\n",
    "        dist_df.to_csv('../intermediate_data/fire_distances.csv', index=False)\n",
    "\n",
    "#Saving the final file\n",
    "dist_df = pd.DataFrame({'OBJECTID': fire_id, 'shortest_dist': shortest_dist_from_edge})\n",
    "dist_df.to_csv('../intermediate_data/fire_distances.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5622e",
   "metadata": {},
   "source": [
    "We will read in the file created above in the event that the programmer saved their outputs and returned to their work later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236290f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading file in as pandas df\n",
    "fire_dist_df = pd.read_csv('../intermediate_data/fire_distances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01811203",
   "metadata": {},
   "source": [
    "Now we will keep only fires which occurr within 1250 miles from town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36adf72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97783 fires within 1250 miles of Pahrump, NV\n"
     ]
    }
   ],
   "source": [
    "#Keeping only fires <1250 miles away\n",
    "lim_fires_df = fire_dist_df.loc[fire_dist_df['shortest_dist']< 1250]\n",
    "print(\"There are {0} fires within 1250 miles of Pahrump, NV\".format(len(lim_fires_df)))\n",
    "\n",
    "#Saving those fires\n",
    "lim_fires_df.to_csv('../intermediate_data/close_fires.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b32c1",
   "metadata": {},
   "source": [
    "Now we will reload the wildfire data to create a table with fire attributes which will later be used to estimate smoke in Pahrump on an annual basis. We are keeping only fires which occurred in or after 1963. The below code loads the table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f658a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading wildfire data to get features\n",
    "wf_file = open('../../USGS_Wildland_Fire_Combined_Dataset.json')\n",
    " \n",
    "#Makes a dictionary from file\n",
    "wf_dict = json.load(wf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be39040",
   "metadata": {},
   "source": [
    "...and the following code extracts the relevent columms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dabc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new lists for relevent columns\n",
    "objectid = []\n",
    "Assigned_Fire_Type = []\n",
    "Fire_Year = []\n",
    "GIS_Acres = []\n",
    "Overlap_Within_1_or_2_Flag = []\n",
    "\n",
    "#Parsing through wf_dict['features'] list for each attribute seeing fire year\n",
    "#if in range, add to the lim_df list\n",
    "for fire in wf_dict['features']:\n",
    "    fire_count = 0\n",
    "    if fire['attributes']['Fire_Year'] >= 1963:\n",
    "        objectid.append(fire['attributes']['OBJECTID'])\n",
    "        Assigned_Fire_Type.append(fire['attributes']['Assigned_Fire_Type'])\n",
    "        Fire_Year.append(fire['attributes']['Fire_Year'])\n",
    "        GIS_Acres.append(fire['attributes']['GIS_Acres'])\n",
    "        Overlap_Within_1_or_2_Flag.append(fire['attributes']['Overlap_Within_1_or_2_Flag'])\n",
    "        fire_count += 1\n",
    "        if fire_count % 1000 == 0:\n",
    "            print(\"Processed {0} fires\".format(fire_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83fc5b",
   "metadata": {},
   "source": [
    "Now we will combine the lists created above into a single pandas dataframe and save it to the intermediate files in the event the programmer wants to return to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d6738b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the feature DF\n",
    "feature_df = pd.DataFrame({'OBJECTID':objectid,\n",
    "                            'Assigned_Fire_Type':Assigned_Fire_Type,\n",
    "                            'Fire_Year':Fire_Year,\n",
    "                            'GIS_Acres':GIS_Acres,\n",
    "                            'Overlap_Within_1_or_2_Flag' : Overlap_Within_1_or_2_Flag})\n",
    "\n",
    "#Saving the feature_df in the event that the programmer wants to come back to it later\n",
    "feature_df.to_csv('../intermediate_data/fire_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f7dcb",
   "metadata": {},
   "source": [
    "Opening the fire features file in the event that the programmer wanted to return to their work later in the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af1c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading fire features in as pandas df\n",
    "fire_feature_df = pd.read_csv('../intermediate_data/fire_features.csv')\n",
    "\n",
    "#Also reading the the close fires as a pandas df\n",
    "close_fires_df= pd.read_csv('../intermediate_data/close_fires.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af972bfd",
   "metadata": {},
   "source": [
    "Next we inner join the post-1963 fire attributes with their distances to later calculate the smoke estimate. We will save this dataframe for later use in the data_processing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e13cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max fire year is 2020\n",
      "The min fire year is 1963\n",
      "The fartherst fire is 1249.99 miles from town\n",
      "The closest fire is 8.52 miles from town\n",
      "There are 81351 fires after 1963 within 1250 miles of Pahrump, NV\n"
     ]
    }
   ],
   "source": [
    "#Inner joining to get only the fires which are after 1963 (inclusive) and within 1250 miles of our town.\n",
    "filtered_fire_df = pd.merge(fire_feature_df, close_fires_df, how = 'inner', left_on='OBJECTID', right_on='OBJECTID')\n",
    "\n",
    "#Saving file\n",
    "filtered_fire_df.to_csv('../intermediate_data/filtered_fire_info.csv', index = False)\n",
    "\n",
    "#Checking the output\n",
    "if filtered_fire_df['Fire_Year'].max() > 2023:\n",
    "    print(\"ERROR - fires after 2023 included in data\")\n",
    "else:\n",
    "    print(\"The max fire year is {0}\".format(filtered_fire_df['Fire_Year'].max()))\n",
    "if filtered_fire_df['Fire_Year'].min() < 1963:\n",
    "    print(\"ERROR - fires before 1963 included in data\")\n",
    "else:\n",
    "    print(\"The min fire year is {0}\".format(filtered_fire_df['Fire_Year'].min()))\n",
    "if filtered_fire_df['shortest_dist'].max() > 1250:\n",
    "    print(\"ERROR - fires beyond 1250 miles included in data\")\n",
    "else:\n",
    "    print(\"The fartherst fire is {0} miles from town\".format(filtered_fire_df['shortest_dist'].max()))\n",
    "    print(\"The closest fire is {0} miles from town\".format(filtered_fire_df['shortest_dist'].min()))\n",
    "print(\"There are {0} fires after 1963 within 1250 miles of Pahrump, NV\".format(len(filtered_fire_df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
